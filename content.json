{"meta":{"title":"Gre的博客","subtitle":null,"description":null,"author":"Zhanggdong","url":"http://yoursite.com"},"pages":[{"title":"文章分类","date":"2018-06-20T00:17:21.000Z","updated":"2018-06-20T00:19:59.907Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2018-06-19T09:56:34.000Z","updated":"2018-06-20T00:10:20.888Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"html 本文链接：&lt;%= post.title %&gt; 作者：Zhanggdong 出处：https://Zhanggdong.github.io/本文基于 知识共享署名-相同方式共享 4.0 国际许可协议发布，欢迎转载，演绎或用于商业目的，但是必须保留本文的署名张贵东及链接。本站总访问量 次, 访客数 人次, 本文总阅读量 次"}],"posts":[{"title":"elasticsearch源码分析(三)Discover模块","slug":"elasticsearch源码分析(三)--Discover模块","date":"2018-05-27T04:12:57.000Z","updated":"2018-06-22T09:54:09.425Z","comments":true,"path":"2018/05/27/elasticsearch源码分析(三)--Discover模块/","link":"","permalink":"http://yoursite.com/2018/05/27/elasticsearch源码分析(三)--Discover模块/","excerpt":"","text":"通过上一篇对Elasticsearch启动的分析，我们知道了ES启动的大致流程，还遗留下几个问题 master选举是在什么模块进行的 ES集群是如何进行Master选举的？ ES是如何维护这些节点的？ 要想进行Master选举，必然要有一套算法机制，以及节点之前的通信连接、判断节点存活状态等。 通过查阅官网资料，我们知道这些功能是在Elasticsearch的发现协议Discovery里面进行的，在官网上，Elasticsearch的Discovery Module有下面几种实现： Azure Classic Discovery：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-discovery-azure-classic.html EC2 Discovery：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-discovery-ec2.html#modules-discovery-ec2 Google Compute Engine Discovery：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-discovery-gce.html Zen Discovery：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-discovery-zen.html ​ 一、Zen Discovery模块介绍这里基本上是官网的翻译，建议还是查看官网文档，翻译不准。。。 Zen Discovery是内置在elasticsearch的默认发现模块。它提供单播发现，但可扩展到支持云环境和其他形式的发现。 禅发现集成了其它模块，例如，节点之间的所有通信是使用transport模块。 它被分离成多个子模块，其解释如下： 1.1 Ping这是一个节点使用发现机制来查找其他节点的过程。 1.2 Unicast单播发现需要一个主机列表，用于将作为GossipRouter。这些宿主可被指定为主机名或IP地址;指定主机名的主机每一轮Ping过程中解析为IP地址。请注意，如果您处于DNS解析度随时间变化的环境中，则可能需要调整JVM安全设置。 建议将单播主机列表维护为集群中符合主节点的节点列表。 单播发现提供以下设置和discovery.zen.ping.unicast前缀： 设置 描述 hosts 数组设置或逗号分隔的设置。每个值的形式应该是host:port或host（如果没有设置，port默认设置会transport.profiles.default.port 回落到transport.tcp.port）。请注意，IPv6主机必须放在括号内。默认为127.0.0.1, [::1] hosts.resolve_timeout 在每轮ping中等待DNS查找的时间量。指定为 时间单位。默认为5秒。 单播发现使用传输模块执行发现。 1.3 master选举作为Ping过程的一部分，集群的主节点要么当选要么加入假期。这是自动完成的。ping的默认超时为3秒 1discovery.zen.ping_timeout（默认为3s） 如果在超时后没有做出决定，则重新启动ping程序。在缓慢或拥塞的网络中，在作出选举决定之前，三秒可能不足以让节点意识到其环境中的其他节点。在这种情况下，应该谨慎地增加超时时间，因为这会减慢选举进程。一旦一个节点决定加入一个现有的已形成的集群，它将发送一个加入请求给主设备（discovery.zen.join_timeout）的超时默认值是ping超时的20倍。 当主节点停止或遇到问题时，群集节点会再次启动ping并选择新的主节点。这种ping测试也可以作为防止（部分）网络故障的保护，其中一个节点可能会不公正地认为主站发生故障。在这种情况下，节点将简单地从其他节点听到关于当前活动的主节点的信息。 如果discovery.zen.master_election.ignore_non_master_pings是true，没有参与资格（节点，其中节点坪node.master是false）的主选期间忽略; 默认值是 false。 可以通过设置node.master来排除节点成为主节点false。 该discovery.zen.minimum_master_nodes套需要加入新当选主为了选举完成并当选节点接受其主控权掌握合格节点的最小数量。相同的设置控制应该成为任何活动集群一部分的活动主节点合格节点的最小数量。如果不满足这个要求，活动的主节点将下台，新的主节点选举将开始。 此设置必须设置为您的主要合格节点的法定人数。建议避免只有两个主节点，因为两个法定人数是两个。因此，任何主节点的损失都将导致无法运行的群集。 1.4 故障检测有两个故障检测进程正在运行。第一种方法是通过主设备对群集中的所有其他节点进行ping操作，并验证它们是否处于活动状态。另一方面，每个节点都会主动确认它是否仍然存在或需要启动选举过程。 以下设置使用discovery.zen.fd前缀控制故障检测过程 ： 设置 描述 ping_interval 一个节点多久发作一次。默认为1s。 ping_timeout 等待ping响应需要多长时间，默认为 30s。 ping_retries 有多少ping故障/超时会导致节点被视为失败。默认为3。 1.5 群集状态更新Cluster state updates主节点是群集中，可以使改变集群状态的唯一节点。主节点一次处理一个集群状态更新，状态改变和发布更新的到集群中的所有其他节点。每个节点接收发布消息，确认它，但还没有立即应用它。如果主节点没有接收来自节点确认的数量至少为discovery.zen.minimum_master_nodes，在时间（由受控discovery.zen.commit_timeout设置，默认值为30秒）内。节点集群状态改变被拒绝。 一旦足够的节点已作出回应，集群状态改变被提交然后消息将被发送到所有结点。然后节点然后进行新的群集状态适用于他们的内部状态。主节点等待所有节点响应，在去队列处理下一个状态更新之前，直到超时，超时时间是在discovery.zen.publish_timeout默认情况下设置为30秒，时间从发布开始时测量h超时设置可以通过动态的改变集群更新设置API 1.6 无主块No master block要使群集完全可操作，它必须具有活动的主节点和一些有主资格的节点，并且主资格的节点必须满足的数目必须满足discovery.zen.minimum_master_nodes设置的值。如果设置 discovery.zen.no_master_block ，那么设置控制在没有活动的主设备时应拒绝哪些操作。 该discovery.zen.no_master_block设置有两个有效选项： all 节点上的所有操作（即读取和写入操作）都将被拒绝。这也适用于api集群状态读取或写入操作，如get索引设置，put映射和集群状态api。 write （默认）写入操作将被拒绝。基于最后一次已知的群集配置，读取操作将成功。这可能会导致部分读取过时的数据，因为此节点可能与群集的其余部分隔离。 该discovery.zen.no_master_block设置不适用于基于节点的apis（例如，群集统计信息，节点信息和节点统计信息apis）。对这些apis的请求不会被阻止，并且可以在任何可用的节点上运行。 1.7 Fault Delection用ping的方式来确定node是否在集群里面 二、Discovery源码分析2.1 Discovery类图 2.2 与Discovery相关的几个类ZenDiscovery.java 模块的主类，也是启动这个模块的入口，由Node.java调用并初始化，几乎涵盖了全部的发现协议的逻辑，是一个高度内聚了类，它有一些成员变量，需要明白他们的意思： pingTimeout：取自discovery.zen.ping_timeout（默认为3s）允许调整选举时间来处理网络慢或拥塞的情况（更高的值确保更少的失败机会） joinTimeout：取自discovery.zen.join_timeout（默认值为ping超时的20倍）。当一个新的node加入集群时，将会发个join的request到master，这个request的timeout即joinTimeout。 joinRetryAttempts：join重试的次数，默认为3次。 joinRetryDelay：重试的间隔，默认为100ms。 maxPingsFromAnotherMaster：容忍其他master发出的,在强制其他或是本地master rejoin之前的次数。 masterElectionIgnoreNonMasters：用来控制在主节点选举时候的ping响应，只有在极端情况下才会使用这个参数，平时一般不用配置，默认值为false 1234有人说，选举master时，node.master为false的节点的投票是不起作用的，这个说法不完全正确：如果discovery.zen.master_election.ignore_non_master_pings设置为true，那么以上说法正确，但是默认是false，也就是说，它们的投票是起作用的，只是它们不可能成为master。所以我觉得，集群机器数不大的话，除了负担特别重的机器，都设置为node.master为true比较妥当。设置需要加入新一轮master选举的“master”候选人的最小数量也就是说，集群中，该值是针对那些node.master=true的来设置的，建议&gt;=num(node.master=true)/2+1.并不是有的朋友解释的，集群机器数量的除以2再加1，当然默认情况下是，因为默认情况下，discovery.zen.master_election.ignore_non_master_pings为false masterElectionWaitForJoinsTimeout：master选举时等待join的timeout,默认是joinTimeout的一半。 其中joinRetryAttempts和maxPingsFromAnotherMaster是一定要大于等于1的。 UnicastZenPing.java 是一个ZenPing 实现类，主要是负责底层和其他Nodes建立并维护连接的任务 PublishClusterStateAction.java 在ZenDiscovery中的变量名是publishClusterState，之前讲过，这些**Action 都是对**Service的封装，因此它主要是用来处理发送事件和处理事件的接口，比如发送一个clusterStateChangeEvent 和处理这个event，都是通过这个类调用 MasterFaultDetection.java 构建完cluster后所有的node用来检测master存活状态的类 NodeFaultDetection.java 构建完cluster后master用来检测其他node存活状态的类 2.3 如何运行我们通过上一篇的分析知道，在ES启动的时候会去实例化Node，然后调用Node#start()方法启动各个module，Discovery是在实例化Node的时候通过guice进行注入的，在Node启动的时候去启动的，代码如下： Node的构造函数中实例化 12345...final DiscoveryModule discoveryModule = new DiscoveryModule(this.settings, threadPool, transportService, namedWriteableRegistry, networkService, clusterService, pluginsService.filterPlugins(DiscoveryPlugin.class));...b.bind(Discovery.class).toInstance(discoveryModule.getDiscovery()); 2.3.1 ZenDiscover的初始化初始化的时候会加载我上段ZenDiscovery模块介绍提到的几个模块，我就不再重复了，值得注意的是Fault Delection的分为两个masterFD和nodesFD；其次还加载了一些对于discover的配置 2.3.2 ZenDiscovery运行其实ZenDiscover的运行就是几个子模块的运行；它是通过Node#start()方法启动的。 在Node#start()方法中：我们可以看到Discovery相关的代码 123456Discovery discovery = injector.getInstance(Discovery.class);clusterService.setDiscoverySettings(discovery.getDiscoverySettings());clusterService.addInitialStateBlock(discovery.getDiscoverySettings().getNoMasterBlock());clusterService.setClusterStatePublisher(discovery::publish);...discovery.startInitialJoin(); 在DiscoveryModule类中， 12345678910111213141516171819202122 Map&lt;String, Supplier&lt;Discovery&gt;&gt; discoveryTypes = new HashMap&lt;&gt;(); discoveryTypes.put(\"zen\", () -&gt; new ZenDiscovery(settings, threadPool, transportService, namedWriteableRegistry, clusterService, hostsProvider)); discoveryTypes.put(\"none\", () -&gt; new NoneDiscovery(settings, clusterService, clusterService.getClusterSettings())); discoveryTypes.put(\"single-node\", () -&gt; new SingleNodeDiscovery(settings, clusterService)); for (DiscoveryPlugin plugin : plugins) &#123; plugin.getDiscoveryTypes(threadPool, transportService, namedWriteableRegistry, clusterService, hostsProvider).entrySet().forEach(entry -&gt; &#123; if (discoveryTypes.put(entry.getKey(), entry.getValue()) != null) &#123; throw new IllegalArgumentException(\"Cannot register discovery type [\" + entry.getKey() + \"] twice\"); &#125; &#125;); &#125;String discoveryType = DISCOVERY_TYPE_SETTING.get(settings); // 这里是函数式编程的用法，详情请百度或者Google Supplier&lt;Discovery&gt; discoverySupplier = discoveryTypes.get(discoveryType); if (discoverySupplier == null) &#123; throw new IllegalArgumentException(\"Unknown discovery type [\" + discoveryType + \"]\"); &#125; Loggers.getLogger(getClass(), settings).info(\"using discovery type [&#123;&#125;]\", discoveryType); discovery = Objects.requireNonNull(discoverySupplier.get()); 由上面的代码可以看出，这里Discovery的实例是由DisdcoveryModule的suppiler 提供。","categories":[{"name":"Elasticsearch源码分析专题","slug":"Elasticsearch源码分析专题","permalink":"http://yoursite.com/categories/Elasticsearch源码分析专题/"}],"tags":[]},{"title":"Elasticsearch源码阅读环境搭建","slug":"elasticsearch源码环境搭建","date":"2018-05-26T04:12:57.000Z","updated":"2018-06-21T09:37:49.035Z","comments":true,"path":"2018/05/26/elasticsearch源码环境搭建/","link":"","permalink":"http://yoursite.com/2018/05/26/elasticsearch源码环境搭建/","excerpt":"","text":"","categories":[{"name":"Elasticsearch源码分析专题","slug":"Elasticsearch源码分析专题","permalink":"http://yoursite.com/categories/Elasticsearch源码分析专题/"}],"tags":[]},{"title":"elasticsearch源码分析(一)--整体架构","slug":"elasticsearch源码分析(一)--整体架构","date":"2018-05-26T04:12:57.000Z","updated":"2018-06-20T01:01:25.040Z","comments":true,"path":"2018/05/26/elasticsearch源码分析(一)--整体架构/","link":"","permalink":"http://yoursite.com/2018/05/26/elasticsearch源码分析(一)--整体架构/","excerpt":"","text":"一、源码主要模块我下载的Elasticsearch的源码版本为5.6.4 从上图来看：Elasticsearch主要包含以下几个模块 distribution：elasticsearch的打包发行相关，将elasticsearch打成各种发行包（zip，deb，rpm，tar）的模块。具体用法如是，在相应的发行版本模块下执行publishToMavenLocal这个Task，如果执行成功的话就会在路径build/distributions下生成对应的发行包，这种打好的包就能在生产服务器上运行。如果自己修改了源码，打包时就需要用到该模块了。 core：核心包，elasticsearch的源码主要在这个里面，Elasticsearch索引管理、集群管理、服务发现、查询、对Lucene操作的封装等都位于该模块 buildSrc：elasticsearch的构建相关的代码，gradle相关依赖配置都在改模块下 client：作为连接elasticsearch的客户端相关代码，它提供了Rest方式（基于Http）、transport （Java Netty内部的通信方式）等方式。 modules：作为elasticsearch除核心外的必备模块相关代码,比如对Netty的封装、父子类查询、重建索引 plugins：作为elasticsearch必备的插件的相关代码，丰富ES的相关功能，比如IK分词器插件、mapper-attachments/ingest-attachment文件处理插件。 二、Elasticsearch整体架构图 服务发现以及选主 ZenDiscovery 恢复以及容灾 搜索引擎 Search ClusterState 网络层 Rest 和 RPC 线程池","categories":[{"name":"Elasticsearch源码分析专题","slug":"Elasticsearch源码分析专题","permalink":"http://yoursite.com/categories/Elasticsearch源码分析专题/"}],"tags":[]},{"title":"elasticsearch源码分析(二)--启动","slug":"elasticsearch源码分析(二)--启动","date":"2018-05-26T04:12:57.000Z","updated":"2018-06-22T01:29:18.196Z","comments":true,"path":"2018/05/26/elasticsearch源码分析(二)--启动/","link":"","permalink":"http://yoursite.com/2018/05/26/elasticsearch源码分析(二)--启动/","excerpt":"","text":"由于最近半年来一直在使用Elasticsearch来做全文检索和ELK统一日志工作，对于ES还是觉得需要细细研究，才能感受到它的魅力，才能有所提高。 我们先提出几个问题： 启动入口在哪个类？ 启动需要做哪些初始化工作？ 如何加载配置文件？ 一、怎么找启动入口在哪个类看源码最头疼的事情就是找入口，相信很多刚开始也是这样，面对那么多模块中的类，很难找到一个切入点，我刚开始看也是这样，对于这样的问题，其实还是自己的积累不够，多学习就是了。 我们先来看看启动的脚本elasticsearch.bat或者elasticsearch.sh 1234567@echo off忽略其他%JAVA% %ES_JAVA_OPTS% %ES_PARAMS% -cp \"%ES_CLASSPATH%\" \"org.elasticsearch.bootstrap.Elasticsearch\" !newparams!ENDLOCAL 看到了org.elasticsearch.bootstrap.Elasticsearch这个类，不用想就是它的启动类。 二、Elasticsearch类做了什么事情我们先来猜想一下，我们下载完Elasticsearch的安装包，一般有两种部署方式：单机部署和集群部署 2.1 单机部署一般我们会修改{Elasticsearch_home}\\config下的elasticsearch.yml文件和jvm.options 在elasticsearch.yml中配置集群名称、节点名称、日志存放路径、数据存放路径、网络IP、http端口（9200）、Netty端口（9300）等 同时还会去初始化一些module，如下图 2.2 集群部署我们会在单机部署的基础上，增加Discovery模块（集群发现）的配置、 有哪些节点参与到集群当中：discovery.zen.ping.unicast.hosts: [“host1”, “host2”] 需要有几个皇子在场才可以选举投票出master：discovery.zen.minimum_master_nodes: 3 2.3 启动流程猜想通过上述分析我们知道，ES集群启动会做一些初始化工作、加载配置文件，加载一下扩展插件，如果是集群启动，还会进行master选举，master选举需要有足够多的节点参与投票，这个参数是可以指定。 三、启动源码分析3.1 Elasticsearch类图 3.2 Elasticsearch#main()方法我们先来看看org.elasticsearch.bootstrap.Elasticsearch#main()方法 12345678910111213141516171819202122public static void main(final String[] args) throws Exception &#123; // we want the JVM to think there is a security manager installed so that if internal policy decisions that would be based on the // presence of a security manager or lack thereof act as if there is a security manager present (e.g., DNS cache policy) System.setSecurityManager(new SecurityManager() &#123; @Override public void checkPermission(Permission perm) &#123; // grant all permissions so that we can later set the security manager to the one that we want &#125; &#125;); LogConfigurator.registerErrorListener(); // 调用构造器 final Elasticsearch elasticsearch = new Elasticsearch(); // 调用main方法，执行完后返回一个状态 int status = main(args, elasticsearch, Terminal.DEFAULT); // 判断状态是否启动成功 if (status != ExitCodes.OK) &#123; exit(status); &#125; &#125; static int main(final String[] args, final Elasticsearch elasticsearch, final Terminal terminal) throws Exception &#123; return elasticsearch.main(args, terminal); &#125; 通过上面的类图关系，我们知道Elasticsearch是一个Command，就是一开始先设置了一个SecurityManager，做一些检查checkPermission(Permission perm)，因此主要还是增加一些启停的hook，配置日志输出，用意看注释吧，接着打印了一些基本参数后则进入init方法，在Command#execute(terminal, options)方法里会调用Bootstrap.init(!daemonize, pidFile, quiet, initialEnv); 12345678910111213141516171819202122public final int main(String[] args, Terminal terminal) throws Exception &#123; if (addShutdownHook()) &#123; shutdownHookThread.set(new Thread(() -&gt; &#123; try &#123; this.close(); &#125; catch (final IOException e) &#123; try ( StringWriter sw = new StringWriter(); PrintWriter pw = new PrintWriter(sw)) &#123; e.printStackTrace(pw); terminal.println(sw.toString()); &#125; catch (final IOException impossible) &#123; // StringWriter#close declares a checked IOException from the Closeable interface but the Javadocs for StringWriter // say that an exception here is impossible throw new AssertionError(impossible); &#125; &#125; &#125;)); // 当JVM关闭时，会执行系统中已经设置的所有通过方法addShutdownHook添加的钩子， // 当系统执行完这些钩子后，jvm才会关闭 Runtime.getRuntime().addShutdownHook(shutdownHookThread.get()); &#125; 配置日志输出Command#main()方法中 12345// 配置日志输出// initialize default for es.logger.level because we will not read the log4j2.propertiesfinal String loggerLevel = System.getProperty(&quot;es.logger.level&quot;, Level.INFO.name());final Settings settings = Settings.builder().put(&quot;logger.level&quot;, loggerLevel).build();LogConfigurator.configureWithoutConfig(settings); LogConfigurator#configureWithoutConfig()方法 123456public static void configureWithoutConfig(final Settings settings) &#123; Objects.requireNonNull(settings); // we initialize the status logger immediately otherwise Log4j will complain when we try to get the context configureStatusLogger(); configureLoggerLevels(settings); &#125; 在Command#mainWithoutErrorHandling(args, terminal)中执行Command，同时会抛出所有的异常给Command#main()方法，真正调用execute(terminal, options)方法执行操作，这是一个抽象方法，通过我们的类图,它的实现类应该是EnvironmentAwareCommand#execute() 123456789101112131415161718192021222324252627@Override protected void execute(Terminal terminal, OptionSet options) throws Exception &#123; // 将配置信息设置到HashMap中 final Map&lt;String, String&gt; settings = new HashMap&lt;&gt;(); for (final KeyValuePair kvp : settingOption.values(options)) &#123; if (kvp.value.isEmpty()) &#123; throw new UserException(ExitCodes.USAGE, \"setting [\" + kvp.key + \"] must not be empty\"); &#125; if (settings.containsKey(kvp.key)) &#123; final String message = String.format( Locale.ROOT, \"setting [%s] already set, saw [%s] and [%s]\", kvp.key, settings.get(kvp.key), kvp.value); throw new UserException(ExitCodes.USAGE, message); &#125; settings.put(kvp.key, kvp.value); &#125; // 检查了elasticsearch的三个环境参数： putSystemPropertyIfSettingIsMissing(settings, \"path.conf\", \"es.path.conf\"); putSystemPropertyIfSettingIsMissing(settings, \"path.data\", \"es.path.data\"); putSystemPropertyIfSettingIsMissing(settings, \"path.home\", \"es.path.home\"); putSystemPropertyIfSettingIsMissing(settings, \"path.logs\", \"es.path.logs\"); // 调用execute方法 execute(terminal, options, createEnv(terminal, settings)); &#125; 该方法也是一个抽象方法，它有很多实现类 在该方法中，会先调用createEnv(terminal, settings)设置环境参数，使用该方法来加载配置文件信息 1234/** Create an &#123;@link Environment&#125; for the command to use. Overrideable for tests. */ protected Environment createEnv(Terminal terminal, Map&lt;String, String&gt; settings) &#123; return InternalSettingsPreparer.prepareEnvironment(Settings.EMPTY, terminal, settings); &#125; 那么这些配置信息怎么跟节点信息关联呢？ 3.3 Elasticsearch#execute()方法直接来看Elasticsearch#execute()方法做了什么？ 12345678910111213141516171819202122232425262728protected void execute(Terminal terminal, OptionSet options, Environment env) throws UserException &#123; // 检查参数是否为空 if (options.nonOptionArguments().isEmpty() == false) &#123; throw new UserException(ExitCodes.USAGE, \"Positional arguments not allowed, found \" + options.nonOptionArguments()); &#125; if (options.has(versionOption)) &#123; if (options.has(daemonizeOption) || options.has(pidfileOption)) &#123; throw new UserException(ExitCodes.USAGE, \"Elasticsearch version option is mutually exclusive with any other option\"); &#125; terminal.println(\"Version: \" + org.elasticsearch.Version.CURRENT + \", Build: \" + Build.CURRENT.shortHash() + \"/\" + Build.CURRENT.date() + \", JVM: \" + JvmInfo.jvmInfo().version()); return; &#125; // 是否以守护线程启动（后台启动 -d） final boolean daemonize = options.has(daemonizeOption); // 进程文件 final Path pidFile = pidfileOption.value(options); // final boolean quiet = options.has(quietOption); try &#123; // 执行初始化方法 init(daemonize, pidFile, quiet, env); &#125; catch (NodeValidationException e) &#123; throw new UserException(ExitCodes.CONFIG, e.getMessage()); &#125; &#125; 该方法主要是检查一些参数，然后调用Elasticsearch#init(daemonize, pidFile, quiet, env)方法，在方法里会调用Bootstrap.init(!daemonize, pidFile, quiet, initialEnv)，而这个方法才是Elasticsearch真正去启动ES。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * This method is invoked by &#123;@link Elasticsearch#main(String[])&#125; to startup elasticsearch. */ static void init( final boolean foreground, final Path pidFile, final boolean quiet, final Environment initialEnv) throws BootstrapException, NodeValidationException, UserException &#123; // Set the system property before anything has a chance to trigger its use initLoggerPrefix(); // force the class initializer for BootstrapInfo to run before // the security manager is installed BootstrapInfo.init(); INSTANCE = new Bootstrap(); final SecureSettings keystore = loadSecureSettings(initialEnv); Environment environment = createEnvironment(foreground, pidFile, keystore, initialEnv.settings()); try &#123; // 配置日志输出 LogConfigurator.configure(environment); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; // 检查自定义配置文件 checkForCustomConfFile(); // 检查是否配置错误 checkConfigExtension(environment.configExtension()); // 如果pidFile文件不为空，则创建pid文件，会在磁盘上持久化一个记录应用pid的文件 if (environment.pidFile() != null) &#123; try &#123; PidFile.create(environment.pidFile(), true); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; &#125; //通过参数foreground和quiet来控制日志输出 final boolean closeStandardStreams = (foreground == false) || quiet; try &#123; if (closeStandardStreams) &#123; final Logger rootLogger = ESLoggerFactory.getRootLogger(); final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class); if (maybeConsoleAppender != null) &#123; Loggers.removeAppender(rootLogger, maybeConsoleAppender); &#125; closeSystOut(); &#125; // fail if somebody replaced the lucene jars checkLucene(); // install the default uncaught exception handler; must be done before security is // initialized as we do not want to grant the runtime permission // setDefaultUncaughtExceptionHandler // 初始化节点信息 Thread.setDefaultUncaughtExceptionHandler( new ElasticsearchUncaughtExceptionHandler(() -&gt; Node.NODE_NAME_SETTING.get(environment.settings()))); // 调用Bootstrap的setup方法和start方法 INSTANCE.setup(true, environment); try &#123; // any secure settings must be read during node construction IOUtils.close(keystore); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; // 调用Bootstrap的start方法 INSTANCE.start(); if (closeStandardStreams) &#123; closeSysError(); &#125; ... 略 参数详解 foreground：标识elasticsearch是否是作为后台守护进程启动的， pidFile：通过parser解析args后得到，实际是解析了默认命令行参数（verbose，E,silent，version，help，quiet，daemonize，pidfile） quiet：同上 initialEnv：Environment实例化的环境参数对象，保存了一些类似于repoFile，configFile，pluginsFile，binFile，libFile等参数。 通过上述的源码阅读，我们发现在该方法中： 主要工作 首先会实例化一个Bootstrap对象 配置log输出器 创建pid文件，会在磁盘上持久化一个记录应用pid的文件 通过参数foreground和quiet来控制日志输出 调用Bootstrap的setup方法和start方法 3.5 Bootstrap#setup()方法1setup(boolean addShutdownHook, Environment environment)throws BootstrapException 该方法主要工作 通过environment生成本地插件控制器 12345678Settings settings = environment.settings(); try &#123; // Spawner类是一个Environment本地插件控制器 spawner.spawnNativePluginControllers(environment); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; 初始化本地资源 12345initializeNatives( environment.tmpFile(), BootstrapSettings.MEMORY_LOCK_SETTING.get(settings), BootstrapSettings.SYSTEM_CALL_FILTER_SETTING.get(settings), BootstrapSettings.CTRLHANDLER_SETTING.get(settings)); ​ 在安全管理器安装之前初始化探针 1initializeProbes(); ​ 添加关闭钩子 1234567891011121314if (addShutdownHook) &#123; Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; try &#123; IOUtils.close(node, spawner); LoggerContext context = (LoggerContext) LogManager.getContext(false); Configurator.shutdown(context); &#125; catch (IOException ex) &#123; throw new ElasticsearchException(\"failed to stop node\", ex); &#125; &#125; &#125;); &#125; ​ 检查jar重复 123456try &#123; // look for jar hell,检查jar重复 JarHell.checkJarHell(); &#125; catch (IOException | URISyntaxException e) &#123; throw new BootstrapException(e); &#125; ​ 在安全管理器安装之前配置日志输出器 1234567// install SM after natives, shutdown hooks, etc. // 安装安全管理器 try &#123; Security.configure(environment, BootstrapSettings.SECURITY_FILTER_BAD_DEFAULTS_SETTING.get(settings)); &#125; catch (IOException | NoSuchAlgorithmException e) &#123; throw new BootstrapException(e); &#125; ​ 安装安全管理器 1234567// install SM after natives, shutdown hooks, etc. // 安装安全管理器 try &#123; Security.configure(environment, BootstrapSettings.SECURITY_FILTER_BAD_DEFAULTS_SETTING.get(settings)); &#125; catch (IOException | NoSuchAlgorithmException e) &#123; throw new BootstrapException(e); &#125; ​ 通过参数environment实例化Node 123456789// 通过参数environment实例化Node node = new Node(environment) &#123; @Override protected void validateNodeBeforeAcceptingRequests( final Settings settings, final BoundTransportAddress boundTransportAddress, List&lt;BootstrapCheck&gt; checks) throws NodeValidationException &#123; BootstrapChecks.check(settings, boundTransportAddress, checks); &#125; &#125;; ​ 3.6 Bootstrap#start()方法1234private void start() throws NodeValidationException &#123; node.start(); keepAliveThread.start(); &#125; 主要工作 启动已经实例化的Node 启动keepAliveThread 线程，这个线程在Bootstrap初始化的时候就已经实例化了，该线程创建了一个计数为1的CountDownLatch，目的是在启动完成后能顺利添加关闭钩子，而这句： 1Runtime.getRuntime().addShutdownHook(new Thread()) 意思就是在jvm中增加一个关闭的钩子，当jvm关闭的时候，会执行系统中已经设置的所有通过方法addShutdownHook添加的钩子，当系统执行完这些钩子后，jvm才会关闭。所以这些钩子可以在jvm关闭的时候进行内存清理、对象销毁等操作。可以看到启动的重点在setup方法中，启动过后就是Node的事了。 keepAliveThhread线程 123456789101112131415161718192021222324private final CountDownLatch keepAliveLatch = new CountDownLatch(1);/** creates a new instance */ Bootstrap() &#123; // 在构造器中就创建keepAliveThread线程 keepAliveThread = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; keepAliveLatch.await(); &#125; catch (InterruptedException e) &#123; // bail out &#125; &#125; &#125;, \"elasticsearch[keepAlive/\" + Version.CURRENT + \"]\"); keepAliveThread.setDaemon(false); // keep this thread alive (non daemon thread) until we shutdown Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; // 这里的钩子执行完毕，才会执行完keepAliveThread线程的run()方法 keepAliveLatch.countDown(); &#125; &#125;); &#125; 3.4 Node类源码解读我们先不看源码，如果是你，会怎么去设计这个Node类？会怎么去加载配置文件信息？ 猜想，我们启动ES都是一个节点Node，如果是集群，会有多个Node，那么我们应该也是通过Node来加载配置文件，加载完配置文件构造一个Config对象，最后初始化一个Node对象。 继续猜想，Node应该是包含一些基本信息、全局环境配置Setting和Environment，节点环境NodeEnvironment、是否为master、是否可以参与投票等。 问题：这些信息设置完毕，如何启动、如何停止？如何加载插件？ 验证猜想，查看类的定义信息 3.4.1 Node初始化我们前面通过分析Bootstrap#setup()方法知道，Node的实例化是在该方法中调用 new Node(environment)进行的，节点的启动是在Bootstrap#start()方法中调用Node#start()方法进行启动的。 123456789// 通过参数environment实例化Node node = new Node(environment) &#123; @Override protected void validateNodeBeforeAcceptingRequests( final Settings settings, final BoundTransportAddress boundTransportAddress, List&lt;BootstrapCheck&gt; checks) throws NodeValidationException &#123; BootstrapChecks.check(settings, boundTransportAddress, checks); &#125; &#125;; 使用google的注入框架Guice的Injector进行注入与获取实例。elasticsearch里面的组件都是用上面的方法进行模块化管理，elasticsearch对guice进行了封装，通过ModulesBuilder类构建elasticsearch的模块： 123456789101112131415161718ModulesBuilder modules = new ModulesBuilder(); // plugin modules must be added here, before others or we can get crazy injection errors... for (Module pluginModule : pluginsService.createGuiceModules()) &#123; modules.add(pluginModule); &#125; final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); modules.add(new NodeModule(this, monitorService)); ClusterModule clusterModule = new ClusterModule(settings, clusterService, pluginsService.filterPlugins(ClusterPlugin.class)); modules.add(clusterModule); IndicesModule indicesModule = new IndicesModule(pluginsService.filterPlugins(MapperPlugin.class)); modules.add(indicesModule); SearchModule searchModule = new SearchModule(settings, false, pluginsService.filterPlugins(SearchPlugin.class)); CircuitBreakerService circuitBreakerService = createCircuitBreakerService(settingsModule.getSettings(), settingsModule.getClusterSettings()); resourcesToClose.add(circuitBreakerService);... Node的实例化主要工作： 设置初始化信息：nodeEnvironment 123456789101112131415161718192021222324252627try &#123; Settings tmpSettings = Settings.builder().put(environment.settings()) .put(Client.CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE).build(); tmpSettings = TribeService.processSettings(tmpSettings); // create the node environment as soon as possible, to recover the node id and enable logging try &#123; nodeEnvironment = new NodeEnvironment(tmpSettings, environment); resourcesToClose.add(nodeEnvironment); &#125; catch (IOException ex) &#123; throw new IllegalStateException(\"Failed to create node environment\", ex); &#125; final boolean hadPredefinedNodeName = NODE_NAME_SETTING.exists(tmpSettings); Logger logger = Loggers.getLogger(Node.class, tmpSettings); final String nodeId = nodeEnvironment.nodeId(); tmpSettings = addNodeNameIfNeeded(tmpSettings, nodeId); if (DiscoveryNode.nodeRequiresLocalStorage(tmpSettings)) &#123; checkForIndexDataInDefaultPathData(tmpSettings, nodeEnvironment, logger); &#125; // this must be captured after the node name is possibly added to the settings final String nodeName = NODE_NAME_SETTING.get(tmpSettings); if (hadPredefinedNodeName == false) &#123; logger.info(\"node name [&#123;&#125;] derived from node ID [&#123;&#125;]; set [&#123;&#125;] to override\", nodeName, nodeId, NODE_NAME_SETTING.getKey()); &#125; else &#123; logger.info(\"node name [&#123;&#125;], node ID [&#123;&#125;]\", nodeName, nodeId); &#125; 打印JVM信息 ​ 初始化pluginsService类 1this.pluginsService = new PluginsService(tmpSettings, environment.modulesFile(), environment.pluginsFile(), classpathPlugins); environment(这里会加载配置文件) 12this.environment = new Environment(this.settings);Environment.assertEquivalent(environment, this.environment); Executors 和threadPool 1234567final List&lt;ExecutorBuilder&lt;?&gt;&gt; executorBuilders = pluginsService.getExecutorBuilders(settings);final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0]));resourcesToClose.add(() -&gt; ThreadPool.terminate(threadPool, 10, TimeUnit.SECONDS));// adds the context to the DeprecationLogger so that it does not need to be injected everywhereDeprecationLogger.setThreadContext(threadPool.getThreadContext());resourcesToClose.add(() -&gt; DeprecationLogger.removeThreadContext(threadPool.getThreadContext())); 我们来看es线程池做了什么？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public ThreadPool(final Settings settings, final ExecutorBuilder&lt;?&gt;... customBuilders) &#123; super(settings); assert Node.NODE_NAME_SETTING.exists(settings); // 将构造好的线程池添加到HashMap中，key是线程池的名称，value是ExecutorBuilder // 每一个线程都是通过ExecutorBuilder来构造 final Map&lt;String, ExecutorBuilder&gt; builders = new HashMap&lt;&gt;(); final int availableProcessors = EsExecutors.boundedNumberOfProcessors(settings); final int halfProcMaxAt5 = halfNumberOfProcessorsMaxFive(availableProcessors); final int halfProcMaxAt10 = halfNumberOfProcessorsMaxTen(availableProcessors); final int genericThreadPoolMax = boundedBy(4 * availableProcessors, 128, 512); builders.put(Names.GENERIC, new ScalingExecutorBuilder(Names.GENERIC, 4, genericThreadPoolMax, TimeValue.timeValueSeconds(30))); builders.put(Names.INDEX, new FixedExecutorBuilder(settings, Names.INDEX, availableProcessors, 200)); builders.put(Names.BULK, new FixedExecutorBuilder(settings, Names.BULK, availableProcessors, 200)); // now that we reuse bulk for index/delete ops builders.put(Names.GET, new FixedExecutorBuilder(settings, Names.GET, availableProcessors, 1000)); builders.put(Names.SEARCH, new FixedExecutorBuilder(settings, Names.SEARCH, searchThreadPoolSize(availableProcessors), 1000)); builders.put(Names.MANAGEMENT, new ScalingExecutorBuilder(Names.MANAGEMENT, 1, 5, TimeValue.timeValueMinutes(5))); // no queue as this means clients will need to handle rejections on listener queue even if the operation succeeded // the assumption here is that the listeners should be very lightweight on the listeners side builders.put(Names.LISTENER, new FixedExecutorBuilder(settings, Names.LISTENER, halfProcMaxAt10, -1)); builders.put(Names.FLUSH, new ScalingExecutorBuilder(Names.FLUSH, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5))); builders.put(Names.REFRESH, new ScalingExecutorBuilder(Names.REFRESH, 1, halfProcMaxAt10, TimeValue.timeValueMinutes(5))); builders.put(Names.WARMER, new ScalingExecutorBuilder(Names.WARMER, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5))); builders.put(Names.SNAPSHOT, new ScalingExecutorBuilder(Names.SNAPSHOT, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5))); builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1)); builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); for (final ExecutorBuilder&lt;?&gt; builder : customBuilders) &#123; if (builders.containsKey(builder.name())) &#123; throw new IllegalArgumentException(\"builder with name [\" + builder.name() + \"] already exists\"); &#125; builders.put(builder.name(), builder); &#125; this.builders = Collections.unmodifiableMap(builders); threadContext = new ThreadContext(settings); final Map&lt;String, ExecutorHolder&gt; executors = new HashMap&lt;&gt;(); for (@SuppressWarnings(\"unchecked\") final Map.Entry&lt;String, ExecutorBuilder&gt; entry : builders.entrySet()) &#123; final ExecutorBuilder.ExecutorSettings executorSettings = entry.getValue().getSettings(settings); final ExecutorHolder executorHolder = entry.getValue().build(executorSettings, threadContext); if (executors.containsKey(executorHolder.info.getName())) &#123; throw new IllegalStateException(\"duplicate executors with name [\" + executorHolder.info.getName() + \"] registered\"); &#125; logger.debug(\"created thread pool: &#123;&#125;\", entry.getValue().formatInfo(executorHolder.info)); executors.put(entry.getKey(), executorHolder); &#125; executors.put(Names.SAME, new ExecutorHolder(DIRECT_EXECUTOR, new Info(Names.SAME, ThreadPoolType.DIRECT))); this.executors = unmodifiableMap(executors); // 最后创建一个1线程的scheduler来执行定时任务 this.scheduler = new ScheduledThreadPoolExecutor(1, EsExecutors.daemonThreadFactory(settings, \"scheduler\"), new EsAbortPolicy()); this.scheduler.setExecuteExistingDelayedTasksAfterShutdownPolicy(false); this.scheduler.setContinueExistingPeriodicTasksAfterShutdownPolicy(false); this.scheduler.setRemoveOnCancelPolicy(true); TimeValue estimatedTimeInterval = ESTIMATED_TIME_INTERVAL_SETTING.get(settings); // 最后创建一个执行timer的线程 this.cachedTimeThread = new CachedTimeThread(EsExecutors.threadName(settings, \"[timer]\"), estimatedTimeInterval.millis()); this.cachedTimeThread.start(); &#125; 原来在ES的threadPool中，根据不同的类型分别分配了不同线程数的一个线程池，而executor由一个executorBuilder来提供，所以submit task的时候也需要指定不同的Name。最后创建一个1线程的scheduler来执行定时任务。最后创建一个执行timer的线程。 再继续往下看Node的构造方法就会看到接下来会new 一堆的services和modules，这里就不一一过了，其共性就是都会绑定刚刚创建的threadPool，已经也会绑定必要的services，某些module本身具有后台线程的话，初始化完成需要调用.start()去启动这些后台线程。 初始化modules实例，通过Guice的Injector进行注入各个Module实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ModulesBuilder modules = new ModulesBuilder();***modules.add(b -&gt; &#123; b.bind(NodeService.class).toInstance(nodeService); b.bind(NamedXContentRegistry.class).toInstance(xContentRegistry); b.bind(PluginsService.class).toInstance(pluginsService); b.bind(Client.class).toInstance(client); b.bind(NodeClient.class).toInstance(client); b.bind(Environment.class).toInstance(this.environment); b.bind(ThreadPool.class).toInstance(threadPool); b.bind(NodeEnvironment.class).toInstance(nodeEnvironment); b.bind(TribeService.class).toInstance(tribeService); b.bind(ResourceWatcherService.class).toInstance(resourceWatcherService); b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService); b.bind(BigArrays.class).toInstance(bigArrays); b.bind(ScriptService.class).toInstance(scriptModule.getScriptService()); b.bind(AnalysisRegistry.class).toInstance(analysisModule.getAnalysisRegistry()); b.bind(IngestService.class).toInstance(ingestService); b.bind(NamedWriteableRegistry.class).toInstance(namedWriteableRegistry); b.bind(MetaDataUpgrader.class).toInstance(metaDataUpgrader); b.bind(MetaStateService.class).toInstance(metaStateService); b.bind(IndicesService.class).toInstance(indicesService); b.bind(SearchService.class).toInstance(newSearchService(clusterService, indicesService, threadPool, scriptModule.getScriptService(), bigArrays, searchModule.getFetchPhase())); b.bind(SearchTransportService.class).toInstance(searchTransportService); b.bind(SearchPhaseController.class).toInstance(new SearchPhaseController(settings, bigArrays, scriptModule.getScriptService())); b.bind(Transport.class).toInstance(transport); b.bind(TransportService.class).toInstance(transportService); b.bind(NetworkService.class).toInstance(networkService); b.bind(UpdateHelper.class).toInstance(new UpdateHelper(settings, scriptModule.getScriptService())); b.bind(MetaDataIndexUpgradeService.class).toInstance(new MetaDataIndexUpgradeService(settings, xContentRegistry, indicesModule.getMapperRegistry(), settingsModule.getIndexScopedSettings(), indexMetaDataUpgraders)); b.bind(ClusterInfoService.class).toInstance(clusterInfoService); b.bind(Discovery.class).toInstance(discoveryModule.getDiscovery()); &#123; RecoverySettings recoverySettings = new RecoverySettings(settings, settingsModule.getClusterSettings()); processRecoverySettings(settingsModule.getClusterSettings(), recoverySettings); b.bind(PeerRecoverySourceService.class).toInstance(new PeerRecoverySourceService(settings, transportService, indicesService, recoverySettings, clusterService)); b.bind(PeerRecoveryTargetService.class).toInstance(new PeerRecoveryTargetService(settings, threadPool, transportService, recoverySettings, clusterService)); &#125; httpBind.accept(b); pluginComponents.stream().forEach(p -&gt; b.bind((Class) p.getClass()).toInstance(p)); &#125; ); injector = modules.createInjector(); 这里面会注入Discovery，ClusterService，Transport Service，还创建了NodeClient用来接收全部其他节点请求。这些都会在往后重点剖析。 3.4.2 启动Node通过在Bootstrap#start()方法中调用Node.start()来启动节点 我们知道，在Node的初始化方法中，Model组件会被添加到绑定的线程当中，那么启动这些只需要调用相应组件的.start()方法即可完成组件的加载 1234567891011121314151617181920public Node start() throws NodeValidationException &#123; if (!lifecycle.moveToStarted()) &#123; return this; &#125; Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(settings)); logger.info(\"starting ...\"); // hack around dependency injection problem (for now...) injector.getInstance(Discovery.class).setAllocationService(injector.getInstance(AllocationService.class)); pluginLifecycleComponents.forEach(LifecycleComponent::start); injector.getInstance(MappingUpdatedAction.class).setClient(client); injector.getInstance(IndicesService.class).start(); injector.getInstance(IndicesClusterStateService.class).start(); injector.getInstance(IndicesTTLService.class).start(); injector.getInstance(SnapshotsService.class).start(); injector.getInstance(SnapshotShardsService.class).start(); injector.getInstance(RoutingService.class).start(); injector.getInstance(SearchService.class).start(); injector.getInstance(MonitorService.class).start(); 3.4.3 Node节点停止 该方法跟node启动差不多，也是调用相关组件的stop方法即可，这里就不再分析了 3.4.4 加载配置文件信息 入口 通过Node的构造方法 123public Node(Settings preparedSettings) &#123; this(InternalSettingsPreparer.prepareEnvironment(preparedSettings, null));&#125; 这就是加载配置文件的入口，它有三个方法 12345678910public static Settings prepareSettings(Settings input) &#123; Settings.Builder output = Settings.builder(); initializeSettings(output, input, Collections.emptyMap()); finalizeSettings(output, null); return output.build(); &#125; public static Environment prepareEnvironment(Settings input, Terminal terminal) &#123; return prepareEnvironment(input, terminal, Collections.emptyMap()); &#125;public static Environment prepareEnvironment(Settings input, Terminal terminal, Map&lt;String, String&gt; properties) &#123;&#125; 在InternalSettingsPreparer类的prepareEnvironment(org.elasticsearch.common.settings.Settings, org.elasticsearch.cli.Terminal, java.util.Map&lt;java.lang.String,java.lang.String&gt;, java.nio.file.Path)方法中进行了配置文件的加载。 加载配置文件的方法 1234567891011121314151617181920212223242526272829303132333435363738394041public static Environment prepareEnvironment(Settings input, Terminal terminal, Map&lt;String, String&gt; properties) &#123; // just create enough settings to build the environment, to get the config dir Settings.Builder output = Settings.builder(); // 初始化输入输出流信息 initializeSettings(output, input, properties); // 构造Environment实例 Environment environment = new Environment(output.build()); // 这个很关键，保证elasticsearch.yml文件中配置的日志路径path.logs生效 output = Settings.builder(); // start with a fresh output boolean settingsFileFound = false; Set&lt;String&gt; foundSuffixes = new HashSet&lt;&gt;(); for (String allowedSuffix : ALLOWED_SUFFIXES) &#123; Path path = environment.configFile().resolve(\"elasticsearch\" + allowedSuffix); if (Files.exists(path)) &#123; if (!settingsFileFound) &#123; try &#123; output.loadFromPath(path); &#125; catch (IOException e) &#123; throw new SettingsException(\"Failed to load settings from \" + path.toString(), e); &#125; &#125; settingsFileFound = true; foundSuffixes.add(allowedSuffix); &#125; &#125; if (foundSuffixes.size() &gt; 1) &#123; throw new SettingsException(\"multiple settings files found with suffixes: \" + Strings.collectionToDelimitedString(foundSuffixes, \",\")); &#125; // re-initialize settings now that the config file has been loaded initializeSettings(output, input, properties); finalizeSettings(output, terminal); // 再次获取Environment实例 environment = new Environment(output.build()); // we put back the path.logs so we can use it in the logging configuration file output.put(Environment.PATH_LOGS_SETTING.getKey(), cleanPath(environment.logsFile().toAbsolutePath().toString())); String configExtension = foundSuffixes.isEmpty() ? null : foundSuffixes.iterator().next(); // 返回Environment实例 return new Environment(output.build(), configExtension); 构建一个默认的Settings的实例 然后用构造出来的新的Settings来加载给定或默认路径下的elasticsearch.yml 然后将方法接受的参数Settings实例也加载到这个新的Settings中。 最后才将日志文件的路径加载进Settings中，这样就保证了elasticsearch.yml文件中配置的日志路径path.logs生效（覆盖该方法参数中的配置）。 最后返回一个Environment的实例，使得Node开始构建 四、总结：通过上述的源码分析，我们知道Elasticsearch节点启动的入口是Elasticsearch#main()方法，在该方法中会进行一些安全管理的设置，去调用Command的main()方法，整个方法执行没有任何异常，则返回ok状态。 Command#main()：会去添加一些钩子、配置日志输出、调用mainWithoutErrorHandling()去执行EnvironmentAwareCommand#execute(terminal, options)方法。 EnvironmentAwareCommand#execute(terminal, options)方法：只是将配置信息设置到HashMap中，检查了elasticsearch的参数path.conf、path.data、path.home、path.logs，最后调用Elasticsearch#execute()方法，execute(terminal, options, createEnv(terminal, settings))会先调用EnvironmentAwareCommand# createEnv(terminal, settings) Elasticsearch#execute()方法：主要是处理参数，调用init(daemonize, pidFile, quiet, env)，真正执行启动的是Bootstrap.init(!daemonize, pidFile, quiet, initialEnv)方法。 Bootstrap.init(!daemonize, pidFile, quiet, initialEnv)：主要是调用setup()方法和start()方法，在setup()方法中主要通过environment生成本地插件控制器spawner、添加钩子、添加安全管理器、检查jar包、创建Node节点。而start()通过启动初始化好的Node和keepAliveThread线程，这个keepAliveThread使用了CountdownLatch计数器为1来保证钩子一定能够关闭。 Node类的初始化：通过设置好的environment来初始化节点，设置nodEnvironment、Environment、设置Node_name、设置线程池（其实是一个HashMap&lt;String,ExecutorBuilder&gt;） ，根据不同的类型分别分配了不同线程数的一个线程池。将创建好的module绑定到创建的ThreadPool。 大致的时序图如下： 现在还遗留着几个问题： master选举是在什么模块进行的 怎么进行master选举 怎么进行节点监控、维护的 留到下一篇再进行分析。。。","categories":[{"name":"Elasticsearch源码分析专题","slug":"Elasticsearch源码分析专题","permalink":"http://yoursite.com/categories/Elasticsearch源码分析专题/"}],"tags":[]},{"title":"Redis面试题整理","slug":"redis/redis","date":"2018-05-26T04:12:57.000Z","updated":"2018-06-20T01:13:19.831Z","comments":true,"path":"2018/05/26/redis/redis/","link":"","permalink":"http://yoursite.com/2018/05/26/redis/redis/","excerpt":"","text":"1、Redis为什么单线程的，能说说它的原理吗Redis使用了单线程架构和I/O多路复用模型来实现高性能的内存数据库服务。Redis使用了单线程架构，预防了多线程可能产生的竞争问题，但是也会引入另外的问题。Redis单线程架构导致无法充分利用CPU多核特性，通常的做法是在一台机器上部署多个Redis实例。 那么Redis使用单线程模型，为什么还那么快： 第一，纯内存访问，Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。第二，非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。 第三，单线程避免了线程切换和竞态产生的消耗。 2、mySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 3、缓存穿透可以介绍⼀一下么？你认为应该如何解决这个问题缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库中查询。 解决思路： 1，如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。 2，根据缓存数据Key的规则。例如我们公司是做机顶盒的，缓存数据以Mac为Key，Mac是有规则，如果不符合规则就过滤掉，这样可以过滤一部分查询。在做缓存规划的时候，Key有一定规则的话，可以采取这种办法。这种办法只能缓解一部分的压力，过滤和系统无关的查询，但是无法根治。 3，采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的BitSet中，不存在的数据将会被拦截掉，从而避免了对底层存储系统的查询压力。关于布隆过滤器，详情查看：基于BitSet的布隆过滤器(Bloom Filter) 大并发的缓存穿透会导致缓存雪崩。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[]}]}